{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NUM_HIDDEN:  50\nLEARNING_RATE:  0.05\nBATCH_SIZE:  64\nNUM_EPOCH:  40\nlen(trainX):  10000\nlen(testX):  5000\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 50176 into shape (784,1)",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-079a24ac5742>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    173\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    174\u001B[0m     \u001B[0;31m# # Train the network and report the accuracy on the training and test set.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 175\u001B[0;31m     \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrainX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtestX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtestY\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-9-079a24ac5742>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(trainX, trainY, testX, testY)\u001B[0m\n\u001B[1;32m    112\u001B[0m             \u001B[0mY\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrainY\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mBATCH_SIZE\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m             \u001B[0;31m# X = np.reshape()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 114\u001B[0;31m             \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mfpRes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfCE\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mW1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mb1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mW2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mb2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    115\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"epoch:\"\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;34m\", batch:\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mj\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\",loss:\"\u001B[0m\u001B[0;34m+\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m             \u001B[0mdelta\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgradCE\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mW1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mb1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mW2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mb2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mfpRes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-9-079a24ac5742>\u001B[0m in \u001B[0;36mfCE\u001B[0;34m(X, Y, W1, b1, W2, b2)\u001B[0m\n\u001B[1;32m     43\u001B[0m     \u001B[0;31m# print(X.shape)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m     \u001B[0;31m## your code here\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 45\u001B[0;31m     \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mNUM_INPUT\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     46\u001B[0m     \u001B[0mZ1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mW1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mb1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[0mH1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mReLU\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mZ1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: cannot reshape array of size 50176 into shape (784,1)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "## Network architecture\n",
    "NUM_INPUT = 784  # Number of input neurons\n",
    "NUM_OUTPUT = 10  # Number of output neurons\n",
    "\n",
    "## Hyperparameters\n",
    "NUM_HIDDEN = 50\n",
    "LEARNING_RATE = 0.05\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCH = 40\n",
    "N = 0\n",
    "\n",
    "print(\"NUM_HIDDEN: \", NUM_HIDDEN)\n",
    "print(\"LEARNING_RATE: \", LEARNING_RATE)\n",
    "print(\"BATCH_SIZE: \", BATCH_SIZE)\n",
    "print(\"NUM_EPOCH: \", NUM_EPOCH)\n",
    "\n",
    "\n",
    "class ForwardPropagationRet:\n",
    "    Z1 = 0\n",
    "    H1 = 0\n",
    "    Z2 = 0\n",
    "    Y_hat = 0\n",
    "\n",
    "class Delta:\n",
    "    deltaW2 = 0\n",
    "    deltab2 = 0\n",
    "    deltaW1 = 0\n",
    "    deltab1 = 0\n",
    "\n",
    "# Load the images and labels from a specified dataset (train or test).\n",
    "def loadData (which):\n",
    "    images = np.load(\"./data/mnist_{}_images.npy\".format(which))\n",
    "    labels = np.load(\"./data/mnist_{}_labels.npy\".format(which))\n",
    "    return images, labels\n",
    "\n",
    "## 1. Forward Propagation\n",
    "# Given training images X, associated labels Y, and a vector of combined weights\n",
    "# and bias terms w, compute the cross-entropy (CE) loss.\n",
    "def fCE (X, Y, W1, b1, W2, b2):\n",
    "    # print(X.shape)\n",
    "    ## your code here\n",
    "    X = np.array(X).reshape(NUM_INPUT,1)\n",
    "    Z1 = np.dot(W1,X) + b1\n",
    "    H1 = ReLU(Z1)\n",
    "    Z2 = np.dot(W2,H1) + b2\n",
    "    Y_hat = Softmax(Z2)\n",
    "\n",
    "    loss = LOSS(BATCH_SIZE, Y, Y_hat)\n",
    "    ret = ForwardPropagationRet()\n",
    "    ret.Y_hat = Y_hat\n",
    "    ret.H1 = H1\n",
    "    ret.Z2 = Z2\n",
    "    ret.Z1 = Z1\n",
    "\n",
    "    return loss,ret\n",
    "\n",
    "    \n",
    "\n",
    "## 2. Backward Propagation\n",
    "# Given training images X, associated labels Y, and a vector of combined weights\n",
    "# and bias terms w, compute the gradient of fCE. \n",
    "def gradCE (X, Y, W1, b1, W2, b2, fpRes):\n",
    "    ## your code here\n",
    "    deltaW2 = 0\n",
    "    deltab2 = 0\n",
    "    deltaW1 = 0\n",
    "    deltab1 = 0\n",
    "    Y_hat = fpRes.Y_hat\n",
    "    H1 = fpRes.H1\n",
    "    Z1 = fpRes.Z1\n",
    "\n",
    "    for i in range(BATCH_SIZE):\n",
    "        deltaW2 = deltaW2 + (Y_hat[i] - Y[i]) * H1[i].T\n",
    "        deltab2 = deltab2 + Y_hat[i] - Y[i]\n",
    "        deltaW1 = deltaW1 + W2.T * (Y_hat[i] - Y[i]) * np.sign(Z1[i]) * X[i].T\n",
    "        deltab1 = deltab1 + W2.T * (Y_hat[i] - Y[i]) * np.sign(Z1[i])\n",
    "\n",
    "    #axis = 0 表示列， axis = 1 表示行\n",
    "    delta = Delta()\n",
    "    delta.deltaW2 = 1/BATCH_SIZE * deltaW2\n",
    "    delta.deltaW1 = 1/BATCH_SIZE * deltaW1\n",
    "    delta.deltab2 = 1/BATCH_SIZE * deltab2\n",
    "    delta.deltab1 = 1/BATCH_SIZE * deltab1\n",
    "\n",
    "    return delta\n",
    "    \n",
    "\n",
    "## 3. Parameter Update\n",
    "# Given training and testing datasets, train the NN.\n",
    "def train(trainX, trainY, testX, testY):\n",
    "    #  Initialize weights randomly\n",
    "    W1 = np.random.randn(392,784)\n",
    "    W2 = np.random.randn(10,392)\n",
    "    b1 = np.random.randn(392,1)\n",
    "    b2 = np.random.rand(10,1)\n",
    "    N = len(trainX)\n",
    "    iter = int((N/BATCH_SIZE))\n",
    "    \n",
    "\n",
    "    for i in range(NUM_EPOCH):\n",
    "        #每次epoch之前打乱数据集\n",
    "        index = np.arange(N)\n",
    "        np.random.shuffle(index)\n",
    "        trainX = trainX[index]\n",
    "        trainY = trainY[index]\n",
    "        for j in range(iter+1):\n",
    "            start = j * BATCH_SIZE\n",
    "            X = trainX[start:start+BATCH_SIZE]\n",
    "            Y = trainY[start:start+BATCH_SIZE]\n",
    "            # X = np.reshape()\n",
    "            loss,fpRes = fCE(X,Y,W1,b1,W2,b2)\n",
    "            print(\"epoch:\"+i+\", batch:\" + j + \",loss:\"+ loss)\n",
    "            delta = gradCE(X,Y,W1,b1,W2,b2,fpRes)\n",
    "            \n",
    "            # update parameters\n",
    "            W2 = W2 - LEARNING_RATE * delta.deltaW2\n",
    "            W1 = W1 - LEARNING_RATE * delta.deltaW1\n",
    "            b1 = b1 - LEARNING_RATE * delta.deltab1\n",
    "            b2 = b2 - LEARNING_RATE * delta.deltab2\n",
    "        \n",
    "        #在测试集上测试结果\n",
    "        test_loss, test_fp_res = fCE(testX,testY,W1,b1,W2,b2)\n",
    "        test_y_hat = test_fp_res.Y_hat\n",
    "        test_predict_label = np.argmax(test_y_hat, axis=1)\n",
    "        test_truth_label = np.argmax(testY, axis=1)\n",
    "        test_accurate_count = 0\n",
    "\n",
    "        for j in range(len(test_predict_label)):\n",
    "            if test_predict_label[j] == test_truth_label[j]:\n",
    "                test_accurate_count += 1\n",
    "\n",
    "        test_accuracy = test_accurate_count / len(testY)\n",
    "        print(\"epoch:\"+i+\", test_accuracy:\" + test_accuracy + \"---------------\")\n",
    "    ## your code here\n",
    "\n",
    "    print(\"completed!\")\n",
    "    pass\n",
    "\n",
    "def ReLU(X):\n",
    "    return np.maximum(X,0)\n",
    "\n",
    "def Softmax(X):\n",
    "    size = len(X)\n",
    "    Y_hat = np.zeros(len(X))\n",
    "    total = 0\n",
    "    for x in X:\n",
    "        total += np.exp(x)\n",
    "\n",
    "    for i,x in X:\n",
    "        Y_hat[i] = np.exp(x)/total\n",
    "\n",
    "    return Y_hat\n",
    "\n",
    "def LOSS(n, Y, Y_hat):\n",
    "    sum = 0\n",
    "    for i in n:\n",
    "        for k in NUM_OUTPUT:\n",
    "            sum = sum + Y[k] * np.log(Y_hat[k])\n",
    "\n",
    "    return -1/n * sum\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    start_time = time.time()\n",
    "    trainX, trainY = loadData(\"train\")\n",
    "    testX, testY = loadData(\"test\")\n",
    "\n",
    "    print(\"len(trainX): \", len(trainX))\n",
    "    print(\"len(testX): \", len(testX))\n",
    "\n",
    "    # # Train the network and report the accuracy on the training and test set.\n",
    "    train(trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}